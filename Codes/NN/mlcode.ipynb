{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('/kaggle/input/new-compressor-data/combined_file_ap_500.csv')  #the respective csv file for the corresponding cluster size can be loaded here\n",
    "\n",
    "# the weights obtained using the 500 cluster size file are later used to test the model on other datasets\n",
    "\n",
    "# first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# basic data exploration\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#  dropping\n",
    "df = df.dropna()\n",
    "\n",
    "# Separating features and target variable 'Multiplier'\n",
    "X = df.drop(columns=['Multiplier', 'Area', 'Power']).values\n",
    "y = df['Multiplier'].values\n",
    "\n",
    "print(\"Unique multipliers:\", df['Multiplier'].value_counts())\n",
    "\n",
    "# Encoding categorical target variable 'Multiplier' to numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Dataset split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_encoded, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The neural network model \n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "\n",
    "# Additional hidden layers\n",
    "model.add(Dense(128, activation='gelu'))\n",
    "model.add(Dense(64, activation='gelu'))\n",
    "model.add(Dense(64, activation='gelu'))\n",
    "model.add(Dense(32, activation='gelu'))\n",
    "\n",
    "# Output layer\n",
    "num_classes = len(set(y_encoded))  # Number of unique classes\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=70, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Training the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=1500, batch_size=32, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "#  Model weights saved after training\n",
    "model.save_weights('model.weights.h5')\n",
    "print(\"Model weights saved successfully.\")\n",
    "\n",
    "# Custom evaluation function\n",
    "def custom_evaluate(model, X_test, y_test, label_encoder):\n",
    "    # Get the predicted probabilities from the model\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    \n",
    "    # Converting predicted probabilities to class labels\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    # Decoding the predicted and actual labels (if using encoded labels)\n",
    "    y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "    y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "    \n",
    "    # Calculating custom accuracy based on conditions\n",
    "    correct = 0\n",
    "    ssim_diff = 0.01\n",
    "    cost_diff = 1\n",
    "    for i in range(len(y_test)):\n",
    "        for j in range(len(y_pred)):\n",
    "            if abs(X_test[j][0] - X_test[i][0]) <= ssim_diff and abs(X_test[j][1] - X_test[i][1]) <= cost_diff:\n",
    "                if y_pred[i] == y_test[j]:\n",
    "                    correct += 1\n",
    "                    break\n",
    "    \n",
    "    accuracy = correct / len(y_pred)\n",
    "    \n",
    "    \n",
    "    print(\"Final Test Accuracy:\", accuracy)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Exact Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Calling the custom evaluation function on the test set\n",
    "custom_accuracy = custom_evaluate(model, X_test, y_test, label_encoder)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# cluster sizes for the dataset\n",
    "sizes = [ 2000, 3000, 4000]\n",
    "\n",
    "\n",
    "# Iterating over all sizes to evaluate each corresponding dataset\n",
    "for size in sizes:\n",
    "    # Loading the new dataset for testing corresponding to the current cluster size\n",
    "    #Here as an example it's being tested on mnist data , hasyv2 or other dataset link can also be used to test them\n",
    "    csv_file = f'/kaggle/input/mnist-data/combined_file_ap_{size}.csv'\n",
    "    new_df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Preprocessing the new dataset (similar to the training dataset)\n",
    "    new_df = new_df.dropna()\n",
    "\n",
    "    # Separation of features and target variable 'Multiplier'\n",
    "    X_new = new_df.drop(columns=['Multiplier', 'Area', 'Power']).values\n",
    "    y_new = new_df['Multiplier'].values\n",
    "\n",
    "    # Combining old and new labels for the LabelEncoder\n",
    "    combined_labels = np.concatenate((y, y_new))\n",
    "\n",
    "    # Re-fitting the LabelEncoder with the combined labels\n",
    "    label_encoder.fit(combined_labels)\n",
    "\n",
    "    # Encoding the new labels\n",
    "    y_new_encoded = label_encoder.transform(y_new)\n",
    "\n",
    "    # Normalizing the features of the new dataset\n",
    "    X_new_normalized = scaler.transform(X_new)\n",
    "\n",
    "    # Loading the saved model weights\n",
    "    model.load_weights('model.weights.h5')\n",
    "    print(f\"Model weights loaded successfully for size {size}.\")\n",
    "\n",
    "    # Test the model on the new data with updated labels\n",
    "    custom_accuracy_new = custom_evaluate(model, X_new_normalized, y_new_encoded, label_encoder)\n",
    "    print(f\"Custom accuracy on the new test dataset (size {size}): {custom_accuracy_new}\")\n",
    "\n",
    "    # Predicting class labels for the new data\n",
    "    y_new_pred_encoded = model.predict(X_new_normalized)\n",
    "\n",
    "    # Converting the predicted probabilities to class labels\n",
    "    y_new_pred = np.argmax(y_new_pred_encoded, axis=1)\n",
    "\n",
    "    # Calculating normal accuracy\n",
    "    normal_accuracy_new = accuracy_score(y_new_encoded, y_new_pred)\n",
    "    print(f\"Normal accuracy on the new dataset (size {size}): {normal_accuracy_new}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5514547,
     "sourceId": 9236509,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5849856,
     "sourceId": 9650104,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
